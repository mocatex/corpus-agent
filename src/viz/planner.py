"""
Visualization Planner Module: Plans visualizations based on user questions and final answers
using a language model to generate SQL queries and plot types.
"""

from __future__ import annotations

import json
from typing import Any, Dict

from openai import OpenAI
from dotenv import load_dotenv

from .schema_summary import schema_summary
from .extra_metadata_glimpse import extra_metadata_glimpse

load_dotenv()
client = OpenAI()


def plan_visualizations(question: str, final_answer: str, run_id: str) -> Dict[str, Any]:
    """
    Plan visualizations based on the given question and final answer.
    the LLM will get a summary of the database schema and a glimpse of the extra_metadata field.
    It will return a structured plan including SQL queries and plot types.
    :param question: the original user question
    :param final_answer: the final answer generated by the pipeline
    :param run_id: the pipeline run ID
    :return: A dict containing the planned visualizations.
    """
    run_id = str(run_id)

    prompt = {"question": question, "final_answer": final_answer, "run_id": run_id, "db_schema": schema_summary(),
              "notes": (
                  "You can propose charts based on SQL queries over these tables. "
                  "Available columns include year, source_domain, rank, os_score, sentiment_score, relevance_score, extra_metadata."
                  "Use WHERE pra.run_id =:run_id (do not inline the UUID)."
              ), "required_output": {
            "charts": [
                {
                    "id": "string",
                    "title": "string",
                    "sql": "string",
                    "plot": {"type": "line|bar", "x": "col", "y": "col"},
                    "filename": "string_ending_with_.png",
                }
            ]
        }, "extra_metadata_glimpse": extra_metadata_glimpse(run_id)}

    prompt["notes"] = (prompt.get("notes", "") + "\n"
                                                 "IMPORTANT: extra_metadata is JSONB and varies by run. "
                                                 "Only use fields that appear in extra_metadata_glimpse.keypaths/examples. "
                                                 "If you need a JSON field in SQL, use Postgres JSON operators like "
                                                 "pra.extra_metadata->'mock_nlp'->>'emotion'. "
                                                 "Use SQLAlchemy params: WHERE pra.run_id = :run_id (do not inline UUID).")

    resp = client.chat.completions.create(
        model="gpt-5-mini",
        messages=[
            {"role": "system", "content": "Return ONLY valid JSON. No markdown. No commentary."},
            {"role": "user", "content": json.dumps(prompt, default=str)},
        ],
        response_format={"type": "json_object"},
    )
    return json.loads(resp.choices[0].message.content)
